{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyFirstMLP.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0g2IaFZgBeFM","colab_type":"text"},"cell_type":"markdown","source":["<h1 align=\"center\">MLP LAB</h1>"]},{"metadata":{"id":"8J6S5AdrCSC7","colab_type":"text"},"cell_type":"markdown","source":["##Install PyTorch + Imports"]},{"metadata":{"id":"EI4X-8LqCW0t","colab_type":"text"},"cell_type":"markdown","source":["##Dataset"]},{"metadata":{"id":"_K_Sw4O0ChXW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","from IPython.core.debugger import set_trace"],"execution_count":0,"outputs":[]},{"metadata":{"id":"__s17MFaAcKk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":183},"outputId":"e78447f7-b799-4e09-ea84-fc34564e1f52","executionInfo":{"status":"ok","timestamp":1527090802889,"user_tz":240,"elapsed":4678,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["import platform\n","import io\n","\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","from matplotlib.pyplot import cm \n","\n","def install_pytorch():\n","    os = platform.system()\n","    if os == \"Linux\":\n","        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n","    elif os == \"Windows\":\n","        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl \n","    !pip3 install torchvision\n","\n","\n","# Install PyTorch\n","install_pytorch()\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n"],"name":"stdout"}]},{"metadata":{"id":"_CAKgnbDECeX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","\n","training_data = dset.MNIST(root='../data', transform = transforms.ToTensor(),train = True, download = True)\n","testing_data = dset.MNIST(root='../data', transform = transforms.ToTensor(),train = False, download = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Jx47RNpGh91","colab_type":"text"},"cell_type":"markdown","source":["**Split Training and Test Data**"]},{"metadata":{"id":"x93nuAcFGhdW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","#train, test = train_test_split(testing_data, test_size = 0.20)\n","\n","batch_size = 100\n","train_loader = torch.utils.data.DataLoader(dataset = training_data,\n","                                           batch_size = batch_size,\n","                                           shuffle = True)\n","test_loader = torch.utils.data.DataLoader(dataset = testing_data,\n","                                          batch_size = batch_size,\n","                                          shuffle = False)\n","#len(train)\n","#len(test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ac2vCmW5Np09","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"b632badf-dc69-4ebd-bcec-8d8a83b20b29","executionInfo":{"status":"ok","timestamp":1527090809718,"user_tz":240,"elapsed":5878,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["d = list(training_data)\n","d[0][0].shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":44}]},{"metadata":{"id":"IZoPC-JXpESt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"fb843d54-ef2c-43e4-8a68-8502ffdd4033","executionInfo":{"status":"ok","timestamp":1527090810013,"user_tz":240,"elapsed":277,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Get Rid of One Dimension via Squeeze\n","\n","image = d[0][0].squeeze()\n","image.shape"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([28, 28])"]},"metadata":{"tags":[]},"execution_count":45}]},{"metadata":{"id":"rz9LLbwPlHVD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"0a8ca126-2a91-4482-e481-20980ae757ad","executionInfo":{"status":"ok","timestamp":1527090810372,"user_tz":240,"elapsed":305,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["use_gpu = torch.cuda.is_available()\n","print(\"GPU Available: {}\".format(use_gpu))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["GPU Available: True\n"],"name":"stdout"}]},{"metadata":{"id":"shf6yLmdtgOj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":368},"outputId":"986a4ad2-a7f3-451f-ee79-fd10f4daf1be","executionInfo":{"status":"ok","timestamp":1527090810810,"user_tz":240,"elapsed":385,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Get a Target\n","target = d[0][1] #d[1][1] works as well. \n","print('Target: {}'.format(target))\n","\n","plt.imshow(image)\n","plt.show()"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Target: 5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fc9eda572e8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"pWPsAsFtre6k","colab_type":"text"},"cell_type":"markdown","source":["##Neutral Network"]},{"metadata":{"id":"24ZdsBYNyqBo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":143},"outputId":"a49c934c-7cad-4cd9-aafe-bd316854eb8a","executionInfo":{"status":"ok","timestamp":1527090811188,"user_tz":240,"elapsed":309,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Create Model and Test Model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","input_size = 784\n","hidden_size = 500\n","num_classes = 10\n","\n","# Write the code to define your neural net below. Don't forget the hyperparameters\n","# like the hidden state sizes for the input layer, hidden layers and output layer\n","class MLP(nn.Module):\n","    def __init__(self,input_size, hidden_size, num_classes):\n","       super(MLP, self).__init__()\n","       self.fc1 = nn.Linear(input_size,hidden_size)\n","       self.fc2 = nn.Linear(hidden_size,hidden_size)\n","       self.fc3 = nn.Linear(hidden_size,num_classes)\n","    \n","    def forward(self, x):        \n","        # your forward pass code\n","        # You will use the Linear/Conv2D classes declared in the constructor\n","        # and use the functional nonlinear functions as activations, such as F.relu\n","        out = F.relu(self.fc1(x))\n","        out = F.relu(self.fc2(out))\n","        # The last layer activation function depends on your loss function and task\n","        out = self.fc3(out)\n","        return out\n","\n","model = MLP(input_size,hidden_size,num_classes)\n","\n","if use_gpu:\n","  #switch model to GPU\n","  model.cuda()\n","     \n","# Print a summary of your model. Everything looks right?\n","print(model)\n","print(\"# parametre: \", sum([param.nelement() for param in model.parameters()]))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["MLP(\n","  (fc1): Linear(in_features=784, out_features=500, bias=True)\n","  (fc2): Linear(in_features=500, out_features=500, bias=True)\n","  (fc3): Linear(in_features=500, out_features=10, bias=True)\n",")\n","# parametre:  648010\n"],"name":"stdout"}]},{"metadata":{"id":"YzAHQxoDu1rw","colab_type":"text"},"cell_type":"markdown","source":["##Loss and Optimizer\n","What loss function will you use? Since you are doing caetegorical classification, what is an appropriate loss function that we saw in class? \n","\n","Hint: check the PyTorch [loss functions docs](https://pytorch.org/docs/master/nn.html?highlight=loss#loss-functions), of course! And while you're at it, grab an [appropriate optimizer](https://pytorch.org/docs/stable/optim.html?highlight=optim#torch.optim.SGD)"]},{"metadata":{"id":"MJ813Tktu5SB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss() # your loss function\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3) # your optimizer, choose one of PyTorch's optimizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NmPxWKTDvAcr","colab_type":"text"},"cell_type":"markdown","source":["## Train/Evaluate Model\n","\n","In this cell you will write a function which loops your dataset for the max number of epochs and trains the model. At the end of each epoch, evaluate the model and save the results!"]},{"metadata":{"id":"lFU7W6GmvDp6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":478},"outputId":"29219e55-43a7-4ae5-c891-f2e2150b5305","executionInfo":{"status":"ok","timestamp":1527090884993,"user_tz":240,"elapsed":73140,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["total_loss = []\n","#epochs = 20\n","\n","num_epochs = 10\n","\n","t0 = time.time()\n","# Start training\n","for epoch in range(num_epochs):\n","    \n","    model.train()\n","    n_iter = 0\n","    train_loss = 0\n","    \n","    for images, labels in train_loader:\n","      \n","      if use_gpu:\n","        #switch tensor type to GPU\n","        images = images.cuda()\n","        labels = labels.cuda()\n","      \n","      \n","      # Flatten the images\n","      images = images.view(-1, 28*28)\n","      \n","      # Zero the gradient buffer + Restart your gradients, Flush the gradiant.\n","      optimizer.zero_grad()  \n","      \n","      # Your code where you use `model` to predict the labels -> Forward\n","      output = model(images)\n","      \n","      # Measure the loss compared to the true target\n","      loss_train = criterion(output, labels)\n","      total_loss.append(train_loss)\n","      #losses_train.append((global_step, train_loss))\n","     \n","    \n","      # Backward\n","      loss_train.backward() #Looks at the history.\n","      \n","      # Update your model with the optimizer!\n","      optimizer.step() \n","    \n","      \n","      # Statistics\n","      train_loss += loss_train.data[0]\n","      n_iter += 1\n","      \n","    tf = time.time()\n","    #print()\n","    print('Epoch: {}/{}, Loss: {:.4f}'.format(\n","          epoch+1, num_epochs, train_loss/n_iter))\n","    print(tf-t0)\n"],"execution_count":50,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1/10, Loss: 2.2882\n","6.649117469787598\n","Epoch: 2/10, Loss: 2.2579\n","13.892943382263184\n","Epoch: 3/10, Loss: 2.2209\n","23.77333688735962\n","Epoch: 4/10, Loss: 2.1711\n","32.89783954620361\n","Epoch: 5/10, Loss: 2.1002\n","39.452975273132324\n","Epoch: 6/10, Loss: 1.9985\n","46.00983119010925\n","Epoch: 7/10, Loss: 1.8570\n","52.71331548690796\n","Epoch: 8/10, Loss: 1.6759\n","59.383137464523315\n","Epoch: 9/10, Loss: 1.4727\n","66.04967164993286\n","Epoch: 10/10, Loss: 1.2772\n","72.72799754142761\n"],"name":"stdout"}]},{"metadata":{"id":"T8IWuyPHvGYZ","colab_type":"text"},"cell_type":"markdown","source":["## Show the results of training"]},{"metadata":{"id":"XKFo1SR5vI35","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1034},"outputId":"dd648508-0438-4979-fd4b-ecbcfd551cf7","executionInfo":{"status":"error","timestamp":1527090885318,"user_tz":240,"elapsed":297,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Set model to evaluate mode\n","model.eval()\n","\n","correct = 0\n","total = 0\n","\n","# Iterate over data.\n","for images, labels in test_loader:  \n","      \n","    # Flatten the images\n","    images = images.view(-1, 28*28)\n","    \n","    # Forward\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)  \n","    _, predicted = torch.max(outputs.data, 1)\n","    \n","    # Statistics\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum()\n","\n","print('Accuracy on the test set: {}%'.format(100 * correct / total))\n","\n"],"execution_count":51,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-b86689699e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-48-1554b3fa549f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# You will use the Linear/Conv2D classes declared in the constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# and use the functional nonlinear functions as activations, such as F.relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# The last layer activation function depends on your loss function and task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.cuda.FloatTensor but found type torch.FloatTensor for argument #4 'mat1'"]}]}]}
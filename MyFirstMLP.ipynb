{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyFirstMLP.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0g2IaFZgBeFM","colab_type":"text"},"cell_type":"markdown","source":["<h1 align=\"center\">MLP LAB</h1>"]},{"metadata":{"id":"8J6S5AdrCSC7","colab_type":"text"},"cell_type":"markdown","source":["##Install PyTorch + Imports"]},{"metadata":{"id":"EI4X-8LqCW0t","colab_type":"text"},"cell_type":"markdown","source":["##Dataset"]},{"metadata":{"id":"_K_Sw4O0ChXW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","from IPython.core.debugger import set_trace"],"execution_count":0,"outputs":[]},{"metadata":{"id":"__s17MFaAcKk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":183},"outputId":"52316d4f-8728-47f7-a77c-4822482ffd24","executionInfo":{"status":"ok","timestamp":1527088882457,"user_tz":240,"elapsed":4528,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["import platform\n","import io\n","\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","from matplotlib.pyplot import cm \n","\n","def install_pytorch():\n","    os = platform.system()\n","    if os == \"Linux\":\n","        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n","    elif os == \"Windows\":\n","        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl \n","    !pip3 install torchvision\n","\n","\n","# Install PyTorch\n","install_pytorch()\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n"],"name":"stdout"}]},{"metadata":{"id":"_CAKgnbDECeX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","\n","training_data = dset.MNIST(root='../data', transform = transforms.ToTensor(),train = True, download = True)\n","testing_data = dset.MNIST(root='../data', transform = transforms.ToTensor(),train = False, download = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Jx47RNpGh91","colab_type":"text"},"cell_type":"markdown","source":["**Split Training and Test Data**"]},{"metadata":{"id":"x93nuAcFGhdW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","#train, test = train_test_split(testing_data, test_size = 0.20)\n","\n","batch_size = 100\n","train_loader = torch.utils.data.DataLoader(dataset = training_data,\n","                                           batch_size = batch_size,\n","                                           shuffle = True)\n","test_loader = torch.utils.data.DataLoader(dataset = testing_data,\n","                                          batch_size = batch_size,\n","                                          shuffle = False)\n","#len(train)\n","#len(test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ac2vCmW5Np09","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"6d29c192-0a55-41a8-d2d0-7077123a279e","executionInfo":{"status":"ok","timestamp":1527088888675,"user_tz":240,"elapsed":5536,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["d = list(training_data)\n","d[0][0].shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"IZoPC-JXpESt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"93eacc7f-0493-4f8d-9ddf-fc3755aa1ab5","executionInfo":{"status":"ok","timestamp":1527088888950,"user_tz":240,"elapsed":241,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Get Rid of One Dimension via Squeeze\n","\n","image = d[0][0].squeeze()\n","image.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([28, 28])"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"rz9LLbwPlHVD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"7a3566d5-ccdd-4bb0-f5f4-b927c421eaf6","executionInfo":{"status":"ok","timestamp":1527088889296,"user_tz":240,"elapsed":270,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["use_gpu = torch.cuda.is_available()\n","print(\"GPU Available: {}\".format(use_gpu))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["GPU Available: True\n"],"name":"stdout"}]},{"metadata":{"id":"shf6yLmdtgOj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":368},"outputId":"52cf37e9-7222-45d8-fec8-e6990f3f431f","executionInfo":{"status":"ok","timestamp":1527088889760,"user_tz":240,"elapsed":389,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Get a Target\n","target = d[0][1] #d[1][1] works as well. \n","print('Target: {}'.format(target))\n","\n","plt.imshow(image)\n","plt.show()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Target: 5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fc9ae8322e8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"pWPsAsFtre6k","colab_type":"text"},"cell_type":"markdown","source":["##Neutral Network"]},{"metadata":{"id":"24ZdsBYNyqBo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":143},"outputId":"1e86787d-7b35-4c4d-fe83-a64079fad110","executionInfo":{"status":"ok","timestamp":1527088890141,"user_tz":240,"elapsed":323,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Create Model and Test Model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","input_size = 784\n","hidden_size = 500\n","num_classes = 10\n","\n","# Write the code to define your neural net below. Don't forget the hyperparameters\n","# like the hidden state sizes for the input layer, hidden layers and output layer\n","class MLP(nn.Module):\n","    def __init__(self,input_size, hidden_size, num_classes):\n","       super(MLP, self).__init__()\n","       self.fc1 = nn.Linear(input_size,hidden_size)\n","       self.fc2 = nn.Linear(hidden_size,hidden_size)\n","       self.fc3 = nn.Linear(hidden_size,num_classes)\n","    \n","    def forward(self, x):        \n","        # your forward pass code\n","        # You will use the Linear/Conv2D classes declared in the constructor\n","        # and use the functional nonlinear functions as activations, such as F.relu\n","        out = F.relu(self.fc1(x))\n","        out = F.relu(self.fc2(out))\n","        # The last layer activation function depends on your loss function and task\n","        out = self.fc3(out)\n","        return out\n","\n","model = MLP(input_size,hidden_size,num_classes)\n","\n","if use_gpu:\n","  #switch model to GPU\n","  model.cuda()\n","     \n","# Print a summary of your model. Everything looks right?\n","print(model)\n","print(\"# parametre: \", sum([param.nelement() for param in model.parameters()]))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["MLP(\n","  (fc1): Linear(in_features=784, out_features=500, bias=True)\n","  (fc2): Linear(in_features=500, out_features=500, bias=True)\n","  (fc3): Linear(in_features=500, out_features=10, bias=True)\n",")\n","# parametre:  648010\n"],"name":"stdout"}]},{"metadata":{"id":"YzAHQxoDu1rw","colab_type":"text"},"cell_type":"markdown","source":["##Loss and Optimizer\n","What loss function will you use? Since you are doing caetegorical classification, what is an appropriate loss function that we saw in class? \n","\n","Hint: check the PyTorch [loss functions docs](https://pytorch.org/docs/master/nn.html?highlight=loss#loss-functions), of course! And while you're at it, grab an [appropriate optimizer](https://pytorch.org/docs/stable/optim.html?highlight=optim#torch.optim.SGD)"]},{"metadata":{"id":"MJ813Tktu5SB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss() # your loss function\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3) # your optimizer, choose one of PyTorch's optimizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NmPxWKTDvAcr","colab_type":"text"},"cell_type":"markdown","source":["## Train/Evaluate Model\n","\n","In this cell you will write a function which loops your dataset for the max number of epochs and trains the model. At the end of each epoch, evaluate the model and save the results!"]},{"metadata":{"id":"lFU7W6GmvDp6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":498},"outputId":"c28d098f-dd8f-468c-fff6-552651ca1c0e","executionInfo":{"status":"ok","timestamp":1527089243732,"user_tz":240,"elapsed":65188,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["total_loss = []\n","#epochs = 20\n","\n","num_epochs = 10\n","\n","t0 = time.time()\n","# Start training\n","for epoch in range(num_epochs):\n","    \n","    model.train()\n","    n_iter = 0\n","    train_loss = 0\n","    \n","    for images, labels in train_loader:\n","      \n","      if use_gpu:\n","        #switch tensor type to GPU\n","        images = images.cuda()\n","        labels = labels.cuda()\n","      \n","      \n","      # Flatten the images\n","      images = images.view(-1, 28*28)\n","      \n","      # Zero the gradient buffer + Restart your gradients, Flush the gradiant.\n","      optimizer.zero_grad()  \n","      \n","      # Your code where you use `model` to predict the labels -> Forward\n","      output = model(images)\n","      \n","      # Measure the loss compared to the true target\n","      loss_train = criterion(output, labels)\n","      total_loss.append(train_loss)\n","      #losses_train.append((global_step, train_loss))\n","     \n","    \n","      # Backward\n","      loss_train.backward() #Looks at the history.\n","      \n","      # Update your model with the optimizer!\n","      optimizer.step() \n","    \n","      \n","      # Statistics\n","      train_loss += loss_train.data[0]\n","      n_iter += 1\n","      \n","    tf = time.time()\n","    #print()\n","    print('Epoch: {}/{}, Loss: {:.4f}'.format(\n","          epoch+1, num_epochs, train_loss/n_iter))\n","    print(tf)\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1/10, Loss: 1.1691\n","1527089185.1628728\n","Epoch: 2/10, Loss: 1.0187\n","1527089191.6106637\n","Epoch: 3/10, Loss: 0.9028\n","1527089198.047134\n","Epoch: 4/10, Loss: 0.8141\n","1527089204.5369658\n","Epoch: 5/10, Loss: 0.7455\n","1527089211.0730042\n","Epoch: 6/10, Loss: 0.6911\n","1527089217.6037655\n","Epoch: 7/10, Loss: 0.6472\n","1527089224.0493062\n","Epoch: 8/10, Loss: 0.6111\n","1527089230.4866753\n","Epoch: 9/10, Loss: 0.5808\n","1527089236.944412\n","Epoch: 10/10, Loss: 0.5550\n","1527089243.3987036\n"],"name":"stdout"}]},{"metadata":{"id":"T8IWuyPHvGYZ","colab_type":"text"},"cell_type":"markdown","source":["## Show the results of training"]},{"metadata":{"id":"XKFo1SR5vI35","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":38},"outputId":"7be8074b-2e44-4752-eb61-29c0d7b1605a","executionInfo":{"status":"ok","timestamp":1527027783315,"user_tz":240,"elapsed":1395,"user":{"displayName":"Airi C.","photoUrl":"//lh6.googleusercontent.com/-mRsT-p21xZI/AAAAAAAAAAI/AAAAAAAAHeU/RHc7qaRZabg/s50-c-k-no/photo.jpg","userId":"109705951704145205723"}}},"cell_type":"code","source":["# Set model to evaluate mode\n","model.eval()\n","\n","correct = 0\n","total = 0\n","\n","# Iterate over data.\n","for images, labels in test_loader:  \n","      \n","    # Flatten the images\n","    images = images.view(-1, 28*28)\n","    \n","    # Forward\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)  \n","    _, predicted = torch.max(outputs.data, 1)\n","    \n","    # Statistics\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum()\n","\n","print('Accuracy on the test set: {}%'.format(100 * correct / total))\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Accuracy on the test set: 78%\n"],"name":"stdout"}]}]}